{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8127d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd82e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Downloading and loading YAMNet model...\n",
      "âœ… YAMNet model loaded from: C:\\Users\\S\\.cache\\kagglehub\\models\\google\\yamnet\\tensorFlow2\\yamnet\\1\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 1: Load Models ==========\n",
    "print(\"ğŸ“¦ Downloading and loading YAMNet model...\")\n",
    "yamnet_path = kagglehub.model_download(\"google/yamnet/tensorFlow2/yamnet\")\n",
    "yamnet_model = tf.saved_model.load(yamnet_path)\n",
    "yamnet_infer = yamnet_model.signatures['serving_default']\n",
    "print(\"âœ… YAMNet model loaded from:\", yamnet_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9d22a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Loading snoring classifier...\n",
      "âŒ Error loading model: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 1024], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'input_layer'}.\n",
      "\n",
      "Exception encountered: Unrecognized keyword arguments: ['batch_shape']\n",
      "Attempting to fix InputLayer config...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'Dense' using config={'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 256, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}.\n\nException encountered: Unknown dtype policy: 'DTypePolicy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Modify the config manually if needed\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m classifier \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnoring_classifier.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputLayer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputLayer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     16\u001b[0m })\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Model loaded successfully after config fix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    255\u001b[0m         filepath,\n\u001b[0;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    264\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'Dense' using config={'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 256, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}.\n\nException encountered: Unknown dtype policy: 'DTypePolicy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Loading snoring classifier model\n",
    "print(\"ğŸ“¦ Loading snoring classifier...\")\n",
    "\n",
    "try:\n",
    "    classifier = tf.keras.models.load_model(\"snoring_classifier.h5\", safe_mode=False)\n",
    "    print(\"âœ… Snoring classifier model loaded.\")\n",
    "except TypeError as e:\n",
    "    print(f\"âŒ Error loading model: {e}\")\n",
    "    print(\"Attempting to fix InputLayer config...\")\n",
    "\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    # Modify the config manually if needed\n",
    "    classifier = load_model(\"snoring_classifier.h5\", custom_objects={\n",
    "        \"InputLayer\": lambda **kwargs: tf.keras.layers.InputLayer(**{k: v for k, v in kwargs.items() if k != \"batch_shape\"})\n",
    "    })\n",
    "\n",
    "    print(\"âœ… Model loaded successfully after config fix.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361501d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ Audio loaded: 649 seconds\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 2: Load Audio ==========\n",
    "audio_path = 'm0.wav'  # Replace with your audio\n",
    "waveform, sr = librosa.load(audio_path, sr=16000)\n",
    "total_seconds = int(librosa.get_duration(y=waveform, sr=sr))\n",
    "print(f\"ğŸ§ Audio loaded: {total_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5c07f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Running snoring detection...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_1\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# 1024-dim embeddings\u001b[39;00m\n\u001b[0;32m     18\u001b[0m embedding_mean \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 20\u001b[0m prediction \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(embedding_mean, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     21\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m timeline\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "# ========== STEP 3: Snoring Detection ==========\n",
    "chunk_samples = sr  # 1 second = 16000 samples\n",
    "timeline = []\n",
    "snoring_seconds = 0\n",
    "\n",
    "print(\"ğŸ” Running snoring detection...\")\n",
    "for sec in range(total_seconds):\n",
    "    start = sec * chunk_samples\n",
    "    end = start + chunk_samples\n",
    "    chunk = waveform[start:end]\n",
    "\n",
    "    if len(chunk) < chunk_samples:\n",
    "        break\n",
    "\n",
    "    chunk_tensor = tf.convert_to_tensor(chunk, dtype=tf.float32)\n",
    "    results = yamnet_infer(waveform=chunk_tensor)\n",
    "    embeddings = results['output_1']  # 1024-dim embeddings\n",
    "    embedding_mean = tf.reduce_mean(embeddings, axis=0).numpy()\n",
    "\n",
    "    prediction = classifier.predict(np.expand_dims(embedding_mean, axis=0), verbose=0)\n",
    "    label = 1 if prediction[0][0] > 0.5 else 0\n",
    "    timeline.append(label)\n",
    "    if label == 1:\n",
    "        snoring_seconds += 1\n",
    "\n",
    "print(f\"âœ… Total snoring detected: {snoring_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STEP 4: OSA Pattern Detection ==========\n",
    "osa_events = []\n",
    "pause_count = 0\n",
    "start_idx = None\n",
    "\n",
    "for i, label in enumerate(timeline):\n",
    "    if label == 0:  # Silence or non-snoring\n",
    "        if start_idx is None:\n",
    "            start_idx = i\n",
    "        pause_count += 1\n",
    "    else:\n",
    "        if pause_count >= 10:  # Apnea-like pause â‰¥10s\n",
    "            osa_events.append((start_idx, i))\n",
    "        pause_count = 0\n",
    "        start_idx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STEP 5: OSA Summary ==========\n",
    "print(\"\\nğŸ©º OSA-Like Event Summary\")\n",
    "print(f\"ğŸ“Œ Audio Duration: {len(timeline)} seconds\")\n",
    "print(f\"ğŸ“Œ Total Snoring Seconds: {snoring_seconds}\")\n",
    "print(f\"ğŸ“Œ Number of Apnea-Like Events: {len(osa_events)}\")\n",
    "for idx, (start, end) in enumerate(osa_events):\n",
    "    print(f\"  ğŸ”´ Event {idx+1}: {start}s to {end}s â†’ {end - start}s pause\")\n",
    "\n",
    "ahi_estimate = (len(osa_events) / (len(timeline) / 60)) * 60\n",
    "print(f\"\\nğŸ“Š Estimated AHI: {ahi_estimate:.2f} events/hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STEP 6: Visualization ==========\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.title(\"Snoring & OSA Pattern Timeline\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "\n",
    "# Fuzzy smoothing\n",
    "timeline_fuzzy = np.convolve(timeline, np.ones(3) / 3, mode='same')\n",
    "\n",
    "# Color code: apnea = orange, snoring = red, non-snoring = blue\n",
    "colors = []\n",
    "for i in range(len(timeline)):\n",
    "    in_apnea = any(start <= i < end for start, end in osa_events)\n",
    "    if in_apnea:\n",
    "        colors.append(\"orange\")\n",
    "    else:\n",
    "        colors.append(\"red\" if timeline[i] == 1 else \"blue\")\n",
    "\n",
    "plt.scatter(range(len(timeline)), timeline_fuzzy, c=colors, s=10)\n",
    "plt.yticks([0, 0.5, 1], ['Non-snoring', 'Threshold', 'Snoring'])\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101049a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ba7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
